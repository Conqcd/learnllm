{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d5ae00",
   "metadata": {},
   "source": [
    "问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "594ce0ab-b031-43d9-806d-66ffd0d6ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch import functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Load the tokenizer and model\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "batch_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "943ecf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09328579",
   "metadata": {},
   "source": [
    "数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91593d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class QADataSet(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.data_path = file_path\n",
    "        self.data = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        with open(self.data_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                json_data = json.loads(line)\n",
    "                question = json_data[\"question\"]\n",
    "                context = json_data[\"context\"]\n",
    "                data.append({\n",
    "                    \"input\": f\"问题是:{question},文章:{context}\",\n",
    "                    \"answer\": json_data[\"answer\"]\n",
    "                })\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2d545df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11616 984\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "dataset = QADataSet('DuReaderQG/train.json')\n",
    "train_dataset, valid_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "test_dataset = QADataSet('DuReaderQG/dev.json')\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7afda05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlength = 0\n",
    "for data in train_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "\n",
    "for data in test_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01b7b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 8080,    13,    75,    11,  3750,   379,  1311,  2049,  1619,  2291,\n",
      "          3720,   207,    17,     3,  1385,    13, 26770,  2095,   679,     7,\n",
      "          2049, 22529,  3286,  1895,  3369,  3073,    48,   200,  1023,   911,\n",
      "           759,  2634,  3350,     4,   152,    19,     7,  2049,  1954,  3652,\n",
      "           312,     3,  2492,     5,  9475,  2049, 22529,  2695,   351,  1954,\n",
      "             4,   511,  1002,     3,  1954,  3652,  2628,    76,   418,  2695,\n",
      "           351,  1954,     3,   186,   594,   311,  1767,     7,    16,   110,\n",
      "          1833, 27859,  9943,  1529,  4827,    94,     3,    20,   288,   504,\n",
      "             3,  2695,   351,  1954,     5,  1229,    52, 12644,     3,   242,\n",
      "           716, 14547,  5704,     4,  3462,     3,  1954,  3652,  1066,   263,\n",
      "          3606,    31, 26770,   740,  2429, 18329,     3,   578,  1833, 27859,\n",
      "          9943,  1529,  4827,    94,  3228,   288,   504,   306,     3,  1954,\n",
      "          3652,  1557, 14547,  5704,     3,  2084,     7,  1954,  3652,   502,\n",
      "         22704,  2974,    66,   930, 21998,   386,     4,  4734, 26475,    24,\n",
      "           165,    50,  1095,  7801,   100,   101,     3,    75,   379,  3606,\n",
      "         26770,   529,  5704,     4,  1027,   263,  3750,  3368,    92,   499,\n",
      "          2049,  7649,  7790,     4,   439,  1766, 13690,     3,   457,  7888,\n",
      "          3460,  2236,     4,    36,  2844,   304,  1318,  1954,    17,  4734,\n",
      "          5704,  3065,   645,  1429,     3,  8657,   571,  2368,  2622,    37,\n",
      "             4,  3175,   126,  6971,    11,  2356,     3,   107, 12420,  2744,\n",
      "          3917,   588,    75,  2049,  3333,  1447, 11127,  2460,     3,    75,\n",
      "           379,  3606, 26770,  5704,     3,   231,  7591,    75,     8,  3750,\n",
      "          6712,   515,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "['问题是', ':', '中国', '是', '世界上', '第', '几个', '核', '试', '爆', '成功的', '国家', '?', ',', '文章', ':', '原子弹', '主要是', '利用', '▁', '核', '裂变', '释放', '出来的', '巨大', '能量', '来', '起', '杀', '伤', '作用', '的一种', '武器', '。', '它', '与', '▁', '核', '反应', '堆', '一样', ',', '依据', '的', '同样是', '核', '裂变', '链', '式', '反应', '。', '按', '理', ',', '反应', '堆', '既然', '能', '实现', '链', '式', '反应', ',', '那么', '只要', '使', '它的', '▁', '中', '子', '增', '殖', '系数', 'k', '大于', '1', ',', '不', '加', '控制', ',', '链', '式', '反应', '的', '规模', '将', '越来越大', ',', '则', '最终', '会发生', '爆炸', '。', '也就是说', ',', '反应', '堆', '也可以', '成为', '一颗', '“', '原子弹', '”。', '实际上', '也是这样', ',', '若', '增', '殖', '系数', 'k', '大于', '1', '而不', '加', '控制', '的话', ',', '反应', '堆', '确实', '会发生', '爆炸', ',', '所谓', '▁', '反应', '堆', '超', '临界', '事故', '就是', '属于', '这样一种', '情况', '。', '|', '1964', '年', '10', '月', '16', '日下午', '3', '点', ',', '中国', '第', '一颗', '原子弹', '成功', '爆炸', '。', '我国', '成为', '世界上', '第五', '个', '拥有', '核', '武装', '的国家', '。', '此', '消息', '一出', ',', '全国', '为之', '欢', '庆', '。', '而', '西方', '世界', '是什么', '反应', '?', '|', '爆炸', '后的', '几', '小时', ',', '情报', '人员', '确认', '事实', '后', '。', '反映', '最', '强烈的', '是', '法国', ',', '他们', '研究人员', '惊', '呼', ':“', '中国', '核', '试验', '取得', '惊人', '成就', ',', '中国', '第', '一颗', '原子弹', '爆炸', ',', '已', '改变了', '中国', '在', '世界上', '的地位', '。”', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(train_dataset[0][\"input\"], truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f45b4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = []\n",
    "    answers = []\n",
    "    for b in batch:\n",
    "        inputs.append(b[\"input\"])\n",
    "        answers.append(b[\"answer\"])\n",
    "\n",
    "    batch_data = tokenizer(inputs, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        answer_token = tokenizer(answers, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(answer_token)\n",
    "        eos_token_id = torch.where(answer_token == tokenizer.eos_token_id)[1]\n",
    "        for idx, eos_id in enumerate(eos_token_id):\n",
    "            answer_token[idx][eos_id + 1:] = -100  # Mask out the tokens after the EOS token\n",
    "        batch_data['labels'] = answer_token\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bef49cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8948dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([7, 309]), 'attention_mask': torch.Size([7, 309]), 'decoder_input_ids': torch.Size([7, 5]), 'labels': torch.Size([7, 5])}\n",
      "tensor([   0,  796, 1916, 1280,    1])\n",
      "tensor([ 796, 1916, 1280,    1, -100])\n",
      "tensor([ 8080,    13,  3930,  1916, 10551,   788,  2347,  8245,    67,     3,\n",
      "         1385,    13,   712,  1916, 10551,   788,  5832,   129, 17947,   113,\n",
      "          146,    21, 10551,   788,     6,  1415, 10551,   788,   944,     5,\n",
      "            3,   712, 12612,  8245,   292,   796,  1916,  1280,  1916, 10551,\n",
      "          788,     3, 19021,  1948,  1916, 10551,   788, 19168, 17140,   106,\n",
      "        10551,  1008,     3,   222,  4096,  4961,   196,     3,  5414,  3758,\n",
      "            3,   166,   207,    27, 10551,   788,   150,  1671,     5,   332,\n",
      "         2206,     3,   167,  3081,  2659,   931,     3,   222,  2818,     5,\n",
      "         1916, 10551,   788,   287,    60,   421,   591,  2687, 12985,    10,\n",
      "            3,  1085,    68,   345,  3493,   138, 16105,  2692,  2316,  1018,\n",
      "            4,    65,   576,  1503,     1,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch['decoder_input_ids'][0])\n",
    "print(batch['labels'][0])\n",
    "print(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f1636",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa321c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def train_loop(dataloader,model,optimizer,epoch, lr_scheduler,total_loss,device):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    model.train()\n",
    "    \n",
    "    for batch,data in enumerate(dataloader,start=1):\n",
    "        data = data.to(device)\n",
    "        output = model(**data)\n",
    "        loss = output.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss / (finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f18c16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu1\n",
    "blue_1 = BLEU(max_ngram_order=1)\n",
    "blue_2 = BLEU(max_ngram_order=2)\n",
    "blue_3 = BLEU(max_ngram_order=3)\n",
    "blue_4 = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0045efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sacrebleu.metrics.bleu.BLEU at 0x1c11da5e4d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb3b7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_loop(dataloader,tokenizer,model,device):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(data[\"input_ids\"],\n",
    "                attention_mask=data[\"attention_mask\"],\n",
    "                max_length=1280,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "        predictions += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "\n",
    "        label_token = data[\"labels\"].cpu().numpy()\n",
    "        label_token = np.where(label_token == -100, tokenizer.pad_token_id, label_token)\n",
    "        decoded_label = tokenizer.batch_decode(label_token, skip_special_tokens=True)\n",
    "\n",
    "        labels += [' '.join(label.strip()) for label in decoded_label]\n",
    "        print(f\"batch: {batch}\")\n",
    "    \n",
    "    bleu1 = blue_1.corpus_score(predictions, [labels]).score\n",
    "    bleu2 = blue_2.corpus_score(predictions, [labels]).score\n",
    "    bleu3 = blue_3.corpus_score(predictions, [labels]).score\n",
    "    bleu4 = blue_4.corpus_score(predictions, [labels]).score\n",
    "    print(f\"BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}\")\n",
    "    return bleu1, bleu2, bleu3, bleu4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4176546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6a0df4813a4022998ab2a499ae4caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(total_loss)\n\u001b[0;32m     20\u001b[0m bleu1, bleu2, bleu3, bleu4 \u001b[38;5;241m=\u001b[39m test_loop(valid_loader, tokenizer, model, device)\n",
      "Cell \u001b[1;32mIn[43], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, optimizer, epoch, lr_scheduler, total_loss, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader,start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1706\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[1;32m-> 1706\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[0;32m   1716\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1717\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1718\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1719\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1720\u001b[0m     )\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1110\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1096\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[0;32m   1097\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         output_attentions,\n\u001b[0;32m   1108\u001b[0m     )\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1110\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:754\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    751\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[1;32m--> 754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:342\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m--> 342\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDenseReluDense(forwarded_states)\n\u001b[0;32m    344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:253\u001b[0m, in \u001b[0;36mT5LayerNorm.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\u001b[39;00m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# half-precision inputs is done in fp32\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m     variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    254\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# convert into half-precision if necessary\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "from transformers import get_scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * epochs,\n",
    ")\n",
    "loss_history = []\n",
    "maxbleusum = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    total_loss = 0.0\n",
    "    total_loss = train_loop(train_loader, model, optimizer, epoch + 1, lr_scheduler, total_loss, device)\n",
    "    loss_history.append(total_loss)\n",
    "    bleu1, bleu2, bleu3, bleu4 = test_loop(valid_loader, tokenizer, model, device)\n",
    "    bleusum = (bleu1 + bleu2 + bleu3 + bleu4) / 4\n",
    "    if bleusum > maxbleusum or epoch == 0:\n",
    "        maxbleusum = bleusum\n",
    "        model.save_pretrained(f\"mengzi-t5-base-finetuned-epoch-{epoch}\")\n",
    "        print(f\"Model saved at epoch {epoch} with BLEU sum: {bleusum:.2f}\")\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca37284",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e995af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop_final(dataloader,tokenizer,model,device,save_path):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    sources = []\n",
    "    model.eval()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(data[\"input_ids\"],\n",
    "                attention_mask=data[\"attention_mask\"],\n",
    "                max_length=1280,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        \n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            data[\"input_ids\"].cpu().numpy(), \n",
    "            skip_special_tokens=True, \n",
    "            use_source_tokenizer=True\n",
    "        )\n",
    "        \n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "        predictions += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "\n",
    "        label_token = data[\"labels\"].cpu().numpy()\n",
    "        label_token = np.where(label_token == -100, tokenizer.pad_token_id, label_token)\n",
    "        decoded_label = tokenizer.batch_decode(label_token, skip_special_tokens=True)\n",
    "\n",
    "        labels += [' '.join(label.strip()) for label in decoded_label]\n",
    "        print(f\"batch: {batch}\")\n",
    "    \n",
    "    bleu1 = blue_1.corpus_score(predictions, [labels]).score\n",
    "    bleu2 = blue_2.corpus_score(predictions, [labels]).score\n",
    "    bleu3 = blue_3.corpus_score(predictions, [labels]).score\n",
    "    bleu4 = blue_4.corpus_score(predictions, [labels]).score\n",
    "    print(f\"BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}\")\n",
    "    results = []\n",
    "    for source, pred, label in zip(sources, predictions, labels):\n",
    "        results.append({\n",
    "            \"context\": source, \n",
    "            \"prediction\": pred, \n",
    "            \"labels\": label\n",
    "        })\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "    return bleu1, bleu2, bleu3, bleu4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "batch: 1\n",
      "batch: 2\n",
      "batch: 3\n",
      "batch: 4\n",
      "batch: 5\n",
      "batch: 6\n",
      "batch: 7\n",
      "batch: 8\n",
      "batch: 9\n",
      "batch: 10\n",
      "batch: 11\n",
      "batch: 12\n",
      "batch: 13\n",
      "batch: 14\n",
      "batch: 15\n",
      "batch: 16\n",
      "batch: 17\n",
      "batch: 18\n",
      "batch: 19\n",
      "batch: 20\n",
      "batch: 21\n",
      "batch: 22\n",
      "batch: 23\n",
      "batch: 24\n",
      "batch: 25\n",
      "batch: 26\n",
      "batch: 27\n",
      "batch: 28\n",
      "batch: 29\n",
      "batch: 30\n",
      "batch: 31\n",
      "batch: 32\n",
      "batch: 33\n",
      "batch: 34\n",
      "batch: 35\n",
      "batch: 36\n",
      "batch: 37\n",
      "batch: 38\n",
      "batch: 39\n",
      "batch: 40\n",
      "batch: 41\n",
      "batch: 42\n",
      "batch: 43\n",
      "batch: 44\n",
      "batch: 45\n",
      "batch: 46\n",
      "batch: 47\n",
      "batch: 48\n",
      "batch: 49\n",
      "batch: 50\n",
      "batch: 51\n",
      "batch: 52\n",
      "batch: 53\n",
      "batch: 54\n",
      "batch: 55\n",
      "batch: 56\n",
      "batch: 57\n",
      "batch: 58\n",
      "batch: 59\n",
      "batch: 60\n",
      "batch: 61\n",
      "batch: 62\n",
      "batch: 63\n",
      "batch: 64\n",
      "batch: 65\n",
      "batch: 66\n",
      "batch: 67\n",
      "batch: 68\n",
      "batch: 69\n",
      "batch: 70\n",
      "batch: 71\n",
      "batch: 72\n",
      "batch: 73\n",
      "batch: 74\n",
      "batch: 75\n",
      "batch: 76\n",
      "batch: 77\n",
      "batch: 78\n",
      "batch: 79\n",
      "batch: 80\n",
      "batch: 81\n",
      "batch: 82\n",
      "batch: 83\n",
      "batch: 84\n",
      "batch: 85\n",
      "batch: 86\n",
      "batch: 87\n",
      "batch: 88\n",
      "batch: 89\n",
      "batch: 90\n",
      "batch: 91\n",
      "batch: 92\n",
      "batch: 93\n",
      "batch: 94\n",
      "batch: 95\n",
      "batch: 96\n",
      "batch: 97\n",
      "batch: 98\n",
      "batch: 99\n",
      "batch: 100\n",
      "batch: 101\n",
      "batch: 102\n",
      "batch: 103\n",
      "batch: 104\n",
      "batch: 105\n",
      "batch: 106\n",
      "batch: 107\n",
      "batch: 108\n",
      "batch: 109\n",
      "batch: 110\n",
      "batch: 111\n",
      "batch: 112\n",
      "batch: 113\n",
      "batch: 114\n",
      "batch: 115\n",
      "batch: 116\n",
      "batch: 117\n",
      "batch: 118\n",
      "batch: 119\n",
      "batch: 120\n",
      "batch: 121\n",
      "batch: 122\n",
      "BLEU-1: 0.01, BLEU-2: 0.00, BLEU-3: 0.00, BLEU-4: 0.00\n",
      "Test BLEU-1: 0.01, BLEU-2: 0.00, BLEU-3: 0.00, BLEU-4: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bleu1, bleu2, bleu3, bleu4 = test_loop_final(test_loader, tokenizer, model, device, \"test_predictions.json\")\n",
    "print(f\"Test BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e01b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

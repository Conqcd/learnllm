{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d5ae00",
   "metadata": {},
   "source": [
    "问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594ce0ab-b031-43d9-806d-66ffd0d6ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65484459c4034642810a0831fb3155a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/725k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hovie.zeng\\.cache\\huggingface\\hub\\models--Langboat--mengzi-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec94e2a29e5842fbad735e5ef0b7b636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7214d88a4d434d8a332dd4a4ac6ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch import functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Load the tokenizer and model\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943ecf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09328579",
   "metadata": {},
   "source": [
    "数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91593d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class QADataSet(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.data_path = file_path\n",
    "        self.data = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        with open(self.data_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                json_data = json.loads(line)\n",
    "                question = json_data[\"question\"]\n",
    "                context = json_data[\"context\"]\n",
    "                data.append({\n",
    "                    \"input\": f\"问题是:{question},文章:{context}\",\n",
    "                    \"answer\": json_data[\"answer\"]\n",
    "                })\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d545df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11616 984\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "dataset = QADataSet('DuReaderQG/train.json')\n",
    "train_dataset, valid_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "test_dataset = QADataSet('DuReaderQG/dev.json')\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afda05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlength = 0\n",
    "for data in train_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "\n",
    "for data in test_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b7b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 8080,    13,   629,    59,   217,   456,   106,   839,   389,     3,\n",
      "          1385,    13,   106,  4281, 24860,  1497,   615,    38,  6077, 24860,\n",
      "           456,     3, 15120,   437,  8278,     9,   456,     3,  1396,    23,\n",
      "           134,   425,  3509,     4,   629,     5,  1337,   184,  5864,     3,\n",
      "           704,    47,  9011,     3,   262, 25202,   306,   122,  1302, 10441,\n",
      "           629, 15781,   427,  3165,   850,  5955,    39,   721,     5,     3,\n",
      "          1085,  1229,     6,  8330,     6,   184, 13521,    62,     4,  2433,\n",
      "         14676,     5,  4790,    23,  1316,   366,     3,   354,  6077,   456,\n",
      "          7655, 23486,   815, 12164,  5378,     3,   982,   217,   133,    98,\n",
      "          4281,   354,  4790,    23,  7655,     5,     4,  7169,  9168,  4790,\n",
      "            23, 11783,  1851,  9168,  2085,     4,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "['问题是', ':', '上海', '去', '什么', '医院', '看', '性', '病', ',', '文章', ':', '看', '诊', '男科', '疾病', '建议', '到', '正规', '男科', '医院', ',', '不要去', '个人', '门诊', '和', '医院', ',', '避免', '上', '当', '受', '骗', '。', '上海', '的', '医疗', '技术', '发达', ',', '水平', '都', '比较高', ',', '不过', '综合来看', '的话', '长', '宁', '区的', '上海', '九龙', '应该', '算是', '首', '屈', '一', '指', '的', ',', '毕竟', '规模', '、', '大夫', '、', '技术', '摆在', '这', '。', '你可以', '到医院', '的', '官网', '上', '查', '一下', ',', '一般', '正规', '医院', '都会有', '该院', '重点', '科室', '的技术', ',', '医生', '什么', '时间', '出', '诊', '一般', '官网', '上', '都会有', '的', '。', '医保', '报销', '官网', '上', '也应该', '会有', '报销', '流程', '。', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(train_dataset[0][\"input\"], truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45b4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = []\n",
    "    answers = []\n",
    "    for b in batch:\n",
    "        inputs.append(b[\"input\"])\n",
    "        answers.append(b[\"answer\"])\n",
    "\n",
    "    batch_data = tokenizer(inputs, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        answer_token = tokenizer(answers, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(answer_token)\n",
    "        eos_token_id = torch.where(answer_token == tokenizer.eos_token_id)[1]\n",
    "        for idx, eos_id in enumerate(eos_token_id):\n",
    "            answer_token[idx][eos_id + 1:] = -100  # Mask out the tokens after the EOS token\n",
    "        batch_data['labels'] = answer_token\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef49cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8948dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([32, 310]), 'attention_mask': torch.Size([32, 310]), 'decoder_input_ids': torch.Size([32, 11]), 'labels': torch.Size([32, 11])}\n",
      "tensor([   0,  100, 4989,  280, 1058,    1,    0,    0,    0,    0,    0])\n",
      "tensor([ 100, 4989,  280, 1058,    1, -100, -100, -100, -100, -100, -100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch['decoder_input_ids'][0])\n",
    "print(batch['labels'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f1636",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa321c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def train_loop(dataloader,model,optimizer,epoch, lr_scheduler,total_loss,device):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    model.train()\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        output = model(**data)\n",
    "        loss = output.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss / (finish_batch_num + progress_bar.n):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18c16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu1\n",
    "blue_1 = BLEU(max_ngram_order=1)\n",
    "blue_2 = BLEU(max_ngram_order=2)\n",
    "blue_3 = BLEU(max_ngram_order=3)\n",
    "blue_4 = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0045efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sacrebleu.metrics.bleu.BLEU at 0x20252bddd50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3b7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_loop(dataloader,tokenizer,model,device):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(data[\"input_ids\"],\n",
    "                attention_mask=data[\"attention_mask\"],\n",
    "                max_length=1280,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "        predictions += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "\n",
    "        label_token = data[\"labels\"].cpu().numpy()\n",
    "        label_token = np.where(label_token == -100, tokenizer.pad_token_id, label_token)\n",
    "        decoded_label = tokenizer.batch_decode(label_token, skip_special_tokens=True)\n",
    "\n",
    "        labels += [' '.join(label.strip()) for label in decoded_label]\n",
    "    \n",
    "    bleu1 = blue_1.corpus_score(predictions, [labels]).score\n",
    "    bleu2 = blue_2.corpus_score(predictions, [labels]).score\n",
    "    bleu3 = blue_3.corpus_score(predictions, [labels]).score\n",
    "    bleu4 = blue_4.corpus_score(predictions, [labels]).score\n",
    "    print(f\"BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}\")\n",
    "    return bleu1, bleu2, bleu3, bleu4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "from transformers import get_scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * epochs,\n",
    ")\n",
    "\n",
    "maxbleusum = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    total_loss = 0.0\n",
    "    total_loss = train_loop(train_loader, model, optimizer, epoch, lr_scheduler, total_loss, device)\n",
    "    bleu1, bleu2, bleu3, bleu4 = test_loop(valid_loader, tokenizer, model, device)\n",
    "    bleusum = (bleu1 + bleu2 + bleu3 + bleu4) / 4\n",
    "    if bleusum > maxbleusum or epoch == 0:\n",
    "        maxbleusum = bleusum\n",
    "        model.save_pretrained(f\"mengzi-t5-base-finetuned-epoch-{epoch}\")\n",
    "        print(f\"Model saved at epoch {epoch} with BLEU sum: {bleusum:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

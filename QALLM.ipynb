{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d5ae00",
   "metadata": {},
   "source": [
    "问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594ce0ab-b031-43d9-806d-66ffd0d6ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch import functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Load the tokenizer and model\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943ecf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09328579",
   "metadata": {},
   "source": [
    "数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91593d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class QADataSet(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.data_path = file_path\n",
    "        self.data = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        with open(self.data_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                json_data = json.loads(line)\n",
    "                question = json_data[\"question\"]\n",
    "                context = json_data[\"context\"]\n",
    "                data.append({\n",
    "                    \"input\": f\"问题是:{question},文章:{context}\",\n",
    "                    \"answer\": json_data[\"answer\"]\n",
    "                })\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d545df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11616 984\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "dataset = QADataSet('DuReaderQG/train.json')\n",
    "train_dataset, valid_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "test_dataset = QADataSet('DuReaderQG/dev.json')\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afda05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlength = 0\n",
    "for data in train_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "\n",
    "for data in test_dataset:\n",
    "    inputs = tokenizer(data[\"input\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "    inputs = tokenizer(data[\"answer\"],truncation=True, padding=True, max_length=10240, return_tensors=\"pt\")\n",
    "    maxlength = max(maxlength, inputs.input_ids.shape[1])\n",
    "maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b7b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 8080,    13, 12825,  1616,    24,   138,    50,  3314,     3,  1385,\n",
      "            13,    16,   696,  8657, 21761,    13, 17194,  4134,     3,  1616,\n",
      "            24,   138,    50,   849,  6242, 21317,   150,  3314,   460,  5622,\n",
      "           218, 11416,     3,   940,  5146,     4,  2249,    38,   678,  3596,\n",
      "             3,   849,  3314,    52,   502,   623, 11416,     4,  4734,     8,\n",
      "           138,    50,   849,  7397, 13020,     3,    75, 13618,   981, 18332,\n",
      "             4,  9788,  7397,  3963,   138,    50,  3314, 13264,  2716,    16,\n",
      "             3,    75, 13618,  1068,  3025,     4,   348, 12825,  3314,  1813,\n",
      "             3,   460,  1359,  4635,  4939,     4,  3013,    18, 23858,  6242,\n",
      "             3,  3314,    18,  8637, 10646,  4939,     4,  1453,     3,   865,\n",
      "          2949,   320,  8588,    34, 22249, 13264,     4,  4734,    75,   404,\n",
      "          2926,     8,  2926,  3314,  2716,    16,    34,   981,  2251,     3,\n",
      "           348, 23858,  1748,   722,  9202,  2836,   487,   138,    50,   849,\n",
      "           126, 14587,  7397,  2926,  2808,     3,  3314,   460,  6733,  8170,\n",
      "          4939,     3, 13332, 20128,  7772,  2993,   644,  1504,     4,  2716,\n",
      "           724,     5,   156,    75,   404,   865,  2949,  1176,    99, 26893,\n",
      "             3,   138,    50,  3314,   460,  5360,  6473,  4939,     3, 13332,\n",
      "            10,    50,   370,  3314,   692,  8985,     4,  1453,     3,  8588,\n",
      "          1812,  3086, 26893,     6,  1417,  2142,  2092,  1238, 26893,   190,\n",
      "         12825,  1545,   108,    34, 14831, 13264,     4,  4734,    16,   696,\n",
      "          8657,   295,  8664,  2431,    19,   669,  6478,     4,   139,   277,\n",
      "           149,   440,  1385,   795,  5626,   143,     3,  3941, 17685,  9907,\n",
      "          5366,  5115, 27455, 10175,  1529, 15802,  2250,  9965,     6,  6074,\n",
      "          5411, 10468,   318,   280,   880,  1152,     3,  7986,  1178,  1500,\n",
      "            19,   509,     4,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "['问题是', ':', '比亚迪', '2017', '年', '4', '月', '销量', ',', '文章', ':', '中', '商', '情报', '网讯', ':', '据统计', '数据显示', ',', '2017', '年', '4', '月', '全球', '新能源', '乘用车', '市场', '销量', '达', '6.', '8', '万辆', ',', '增长', '30%', '。', '预计', '到', '今年', '年底', ',', '全球', '销量', '将', '超', '百', '万辆', '。', '|', '在', '4', '月', '全球', '新能源汽车', '市场中', ',', '中国', '车企', '表现', '亮眼', '。', '在全球', '新能源汽车', '企', '4', '月', '销量', '前十', '排名', '中', ',', '中国', '车企', '占', '一半', '。', '其中', '比亚迪', '销量', '最高', ',', '达', '60', '33', '辆', '。', '其次', '为', '北汽', '新能源', ',', '销量', '为', '57', '74', '辆', '。', '此外', ',', '知', '豆', '跟', '吉利', '也', '跻身', '前十', '。', '|', '中国', '品牌', '车型', '在', '车型', '销量', '排名', '中', '也', '表现', '不错', ',', '其中', '北汽', 'E', 'C', '180', '首次', '获得', '4', '月', '全球', '最', '畅销', '新能源汽车', '车型', '冠军', ',', '销量', '达', '43', '52', '辆', ',', '创下', '微型', '电动车', '的新', '销售', '记录', '。', '排名', '第二', '的', '也是', '中国', '品牌', '知', '豆', 'D', '2', 'EV', ',', '4', '月', '销量', '达', '37', '09', '辆', ',', '创下', '了', '月', '度', '销量', '历史', '新高', '。', '此外', ',', '吉利', '帝', '豪', 'EV', '、', '康', '迪', 'K', '17', 'EV', '以及', '比亚迪', 'e', '5', '也', '位列', '前十', '。', '|', '中', '商', '情报', '网', '倡导', '尊重', '与', '保护', '知识产权', '。', '如', '发现', '本', '站', '文章', '存在', '版权', '问题', ',', '烦', '请联系', 'ed', 'it', 'or', '@', 'as', 'k', 'ci', '.', 'com', '、', '07', '55', '-8', '20', '9', '50', '14', ',', '我们将', '及时', '沟通', '与', '处理', '。', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(train_dataset[0][\"input\"], truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45b4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = []\n",
    "    answers = []\n",
    "    for b in batch:\n",
    "        inputs.append(b[\"input\"])\n",
    "        answers.append(b[\"answer\"])\n",
    "\n",
    "    batch_data = tokenizer(inputs, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        answer_token = tokenizer(answers, truncation=True, padding=True, max_length=1280, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(answer_token)\n",
    "        eos_token_id = torch.where(answer_token == tokenizer.eos_token_id)[1]\n",
    "        for idx, eos_id in enumerate(eos_token_id):\n",
    "            answer_token[idx][eos_id + 1:] = -100  # Mask out the tokens after the EOS token\n",
    "        batch_data['labels'] = answer_token\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef49cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8948dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([8, 392]), 'attention_mask': torch.Size([8, 392]), 'decoder_input_ids': torch.Size([8, 5]), 'labels': torch.Size([8, 5])}\n",
      "tensor([  0, 409, 358, 488,   1])\n",
      "tensor([ 409,  358,  488,    1, -100])\n",
      "tensor([ 8080,    13,   713,  1175, 15231, 10640,  3548,     3,  1385,    13,\n",
      "          569, 10640,    13,   409,   358,   488,     4,   815,    45,  2328,\n",
      "         2519,    54,  2833,   409,   358,     3, 10654,    33, 16466,   381,\n",
      "           54,  1228,   409,   358,   488,     3,  1066,    54,  1555,   409,\n",
      "          358,    33,     4,     8,  3110,     3, 14437,  3985, 10785,    71,\n",
      "          820,   179,  2833,   409,   358,   488, 18662,     3,  6033,  4236,\n",
      "         2833,   409,   358,   488,   130,  3344,     3,  3092,   134,   152,\n",
      "           54,    38,  7266,    96,     3,   199,  2833, 10640,  2052,     5,\n",
      "        25331,     3,  2040,   362,  6155,   870,     3,  3552,   530,   819,\n",
      "            3,   130, 10124,     4,  8139, 10640,  2774,     3, 10451,    38,\n",
      "         1933,    59,  3445,  1116,  8564,     3,   177,  1066, 10415,  2984,\n",
      "         2984,     3,   495,    96,   162,  3801,  5566,     4,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch['decoder_input_ids'][0])\n",
    "print(batch['labels'][0])\n",
    "print(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f1636",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa321c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def train_loop(dataloader,model,optimizer,epoch, lr_scheduler,total_loss,device):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    model.train()\n",
    "    \n",
    "    for batch,data in enumerate(dataloader,start=1):\n",
    "        data = data.to(device)\n",
    "        output = model(**data)\n",
    "        loss = output.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss / (finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18c16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu1\n",
    "blue_1 = BLEU(max_ngram_order=1)\n",
    "blue_2 = BLEU(max_ngram_order=2)\n",
    "blue_3 = BLEU(max_ngram_order=3)\n",
    "blue_4 = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0045efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sacrebleu.metrics.bleu.BLEU at 0x2264d61c1d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3b7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_loop(dataloader,tokenizer,model,device):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(data[\"input_ids\"],\n",
    "                attention_mask=data[\"attention_mask\"],\n",
    "                max_length=1280,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "        predictions += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "\n",
    "        label_token = data[\"labels\"].cpu().numpy()\n",
    "        label_token = np.where(label_token == -100, tokenizer.pad_token_id, label_token)\n",
    "        decoded_label = tokenizer.batch_decode(label_token, skip_special_tokens=True)\n",
    "\n",
    "        labels += [' '.join(label.strip()) for label in decoded_label]\n",
    "    \n",
    "    bleu1 = blue_1.corpus_score(predictions, [labels]).score\n",
    "    bleu2 = blue_2.corpus_score(predictions, [labels]).score\n",
    "    bleu3 = blue_3.corpus_score(predictions, [labels]).score\n",
    "    bleu4 = blue_4.corpus_score(predictions, [labels]).score\n",
    "    print(f\"BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}\")\n",
    "    return bleu1, bleu2, bleu3, bleu4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0df2d933da46aaa9c0306087e30ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "from transformers import get_scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * epochs,\n",
    ")\n",
    "loss_history = []\n",
    "maxbleusum = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    total_loss = 0.0\n",
    "    total_loss = train_loop(train_loader, model, optimizer, epoch + 1, lr_scheduler, total_loss, device)\n",
    "    loss_history.append(total_loss)\n",
    "    bleu1, bleu2, bleu3, bleu4 = test_loop(valid_loader, tokenizer, model, device)\n",
    "    bleusum = (bleu1 + bleu2 + bleu3 + bleu4) / 4\n",
    "    if bleusum > maxbleusum or epoch == 0:\n",
    "        maxbleusum = bleusum\n",
    "        model.save_pretrained(f\"mengzi-t5-base-finetuned-epoch-{epoch}\")\n",
    "        print(f\"Model saved at epoch {epoch} with BLEU sum: {bleusum:.2f}\")\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca37284",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

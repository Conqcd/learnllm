{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91055237",
   "metadata": {},
   "source": [
    "学习Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a73403",
   "metadata": {},
   "source": [
    "各类模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f64edde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant. Answer the question: What is Langchain?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "#这个模板完全就是一个字符串模板，使用`{}`来表示变量的位置。\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"You are a helpful assistant. Answer the question: {question}\",\n",
    ")\n",
    "prompt_template.format(question=\"What is Langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329fe28f-0bbb-4138-9d32-d8de3ef1db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "#这个模板用于聊天场景，支持多轮对话的格式化。方便你管理对话的上下文。\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332c913",
   "metadata": {},
   "source": [
    "和上面类似，只不过把System合Human的包装变了种模样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8896f3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is your name, Alice?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "#这个模板用于人类消息的格式化，适合需要用户输入的场景。\n",
    "human_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "                ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"What is your name, {name}?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "human_prompt_template.format_messages(name=\"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9079c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='You are a helpful assistant. Answer the question: What is Langchain?', additional_kwargs={}, response_metadata={}, role='C')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "#这个模板用于聊天消息的格式化，支持更复杂的消息结构。单条信息\n",
    "chat_message_prompt_template = ChatMessagePromptTemplate.from_template(\n",
    "    role = 'C',\n",
    "    template=\"You are a helpful assistant. Answer the question: {question}\"\n",
    ")\n",
    "chat_message_prompt_template.format(question=\"What is Langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dab414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='最小哈希MinHashing 最小哈希是我们流程的下一步，允许我们将稀疏向量转换为稠密向量。现在，作为预警 - 这个过程的这一部分最初可能看起来令人困惑 - 但一旦你理解它就非常简单了。我们有稀疏向量，我们所做的是为签名中的每个位置随机生成一个 minhash 函数（例如稠密向量）。因此，如果我们想创建一个包含 20 个数字的稠密向量/签名，我们将使用 20 个 minhash 函数。现在，这些 MinHash 函数只是数字的随机顺序——我们从 1 数到最终数字（即 len(vocab)）。由于这些数字的顺序是随机的，我们可能会发现数字1位于随机化 MinHash 函数的第 57 位。签名值是通过首先采用一个随机排列的计数向量（从 1 到 len(vocab)+1）来创建的，并在稀疏向量中找到与 1 对齐的最小数。', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='你好，我是AI助手。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='总结一下这段对话的要点。用50个字。', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# MessagesPlaceholder 用于在聊天模板中占位，表示将来会填充的消息。\n",
    "messages_placeholder = MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "human_message = \"总结一下这段对话的要点。用{word_count}个字。\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(\n",
    "    human_message\n",
    ")\n",
    "\n",
    "chat_promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        messages_placeholder,\n",
    "        human_message_prompt_template\n",
    "    ]\n",
    ")\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "# 创建一个包含多条消息的列表\n",
    "messages = [\n",
    "    HumanMessage(content=\"最小哈希MinHashing \"\n",
    "        \"最小哈希是我们流程的下一步，允许我们将稀疏向量转换为稠密向量。现在，作为预警 - 这个过程的这一部分最初可能看起来令人困惑 - 但一旦你理解它就非常简单了。\"\n",
    "        \"我们有稀疏向量，我们所做的是为签名中的每个位置随机生成一个 minhash 函数（例如稠密向量）。\"\n",
    "        \"因此，如果我们想创建一个包含 20 个数字的稠密向量/签名，我们将使用 20 个 minhash 函数。\"\n",
    "        \"现在，这些 MinHash 函数只是数字的随机顺序——我们从 1 数到最终数字（即 len(vocab)）。由于这些数字的顺序是随机的，我们可能会发现数字1位于随机化 MinHash 函数的第 57 位。\"\n",
    "        \"签名值是通过首先采用一个随机排列的计数向量（从 1 到 len(vocab)+1）来创建的，并在稀疏向量中找到与 1 对齐的最小数。\"\n",
    "        ),\n",
    "    AIMessage(content=\"你好，我是AI助手。\")\n",
    "]\n",
    "\n",
    "# 使用 ChatPromptTemplate 格式化消息\n",
    "formatted_messages = chat_promt.format_messages(messages=messages, word_count=50)\n",
    "formatted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f4a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
